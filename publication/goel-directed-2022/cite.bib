@inproceedings{goel_directed_2022,
 abstract = {Processing visual data on mobile devices has many applications, e.g., emergency response and tracking. State-of-the-art computer vision techniques rely on large Deep Neural Networks (DNNs) that are usually too power-hungry to be deployed on resource-constrained edge devices. Many techniques improve DNN efficiency of DNNs by compromising accuracy. However, the accuracy and efficiency of these techniques cannot be adapted for diverse edge applications with different hardware constraints and accuracy requirements. This paper demonstrates that a recent, efficient tree-based DNN architecture, called the hierarchical DNN, can be converted into a Directed Acyclic Graph-based (DAG) architecture to provide tunable accuracy-efficiency tradeoff options. We propose a systematic method that identifies the connections that must be added to convert the tree to a DAG to improve accuracy. We conduct experiments on popular edge devices and show that increasing the connectivity of the DAG improves the accuracy to within 1% of the existing high accuracy techniques. Our approach requires 93% less memory, 43% less energy, and 49% fewer operations than the high accuracy techniques, thus providing more accuracy-efficiency configurations.},
 address = {New York, NY, USA},
 author = {Goel, Abhinav and Tung, Caleb and Eliopoulos, Nick and Hu, Xiao and Thiruvathukal, George K. and Davis, James C. and Lu, Yung-Hsiang},
 booktitle = {Proceedings of the ACM/IEEE International Symposium on Low Power Electronics and Design},
 doi = {10.1145/3531437.3539723},
 isbn = {978-1-4503-9354-6},
 note = {event-place: Boston, MA, USA},
 publisher = {Association for Computing Machinery},
 series = {ISLPED '22},
 title = {Directed Acyclic Graph-Based Neural Networks for Tunable Low-Power Computer Vision},
 url = {https://doi.org/10.1145/3531437.3539723},
 year = {2022}
}
