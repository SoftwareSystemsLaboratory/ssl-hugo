@inproceedings{hu_crowdsourcing_2020,
 abstract = {Despite many exciting innovations in computer vision, recent studies reveal a number of risks in existing computer vision systems, suggesting results of such systems may be unfair and untrustworthy. Many of these risks can be partly attributed to the use of a training image dataset that exhibits sampling biases and thus does not accurately reflect the real visual world. Being able to detect potential sampling biases in the visual dataset prior to model development is thus essential for mitigating the fairness and trustworthy concerns in computer vision. In this paper, we propose a three-step crowdsourcing workflow to get humans into the loop for facilitating bias discovery in image datasets. Through two sets of evaluation studies, we find that the proposed workflow can effectively organize the crowd to detect sampling biases in both datasets that are artificially created with designed biases and real-world image datasets that are widely used in computer vision research and system development.},
 address = {New York, NY, USA},
 author = {Hu, Xiao and Wang, Haobo and Vegesana, Anirudh and Dube, Somesh and Yu, Kaiwen and Kao, Gore and Chen, Shuo-Han and Lu, Yung-Hsiang and Thiruvathukal, George K. and Yin, Ming},
 booktitle = {Proceedings of The Web Conference 2020},
 doi = {10.1145/3366423.3380063},
 isbn = {978-1-4503-7023-3},
 note = {event-place: Taipei, Taiwan},
 pages = {2955--2961},
 publisher = {Association for Computing Machinery},
 series = {WWW '20},
 title = {Crowdsourcing Detection of Sampling Biases in Image Datasets},
 url = {https://doi.org/10.1145/3366423.3380063},
 year = {2020}
}
